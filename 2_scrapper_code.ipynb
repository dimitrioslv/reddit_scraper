{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f8af4d-6387-4351-a139-7cbb106db6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with imports\n",
    "import requests\n",
    "from datetime import time\n",
    "import pandas as pd\n",
    "import schedule \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23d6f51-397b-4ab2-8604-a9a80ce2a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info we need to auth\n",
    "CLIENT_ID = 'cEnM0dAv-0q7aC2ydC8fUQ'\n",
    "SECRET_KEY = 'xejVnIGWyZoQuHFNZqaU8ckOjTVqCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d33f03-6078-472f-8695-247e0f54cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth with pswrd file\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
    "\n",
    "with open('pw.txt','r') as f:\n",
    "    pw = f.read()\n",
    "    \n",
    "data = {\n",
    "    'grant_type':'password',\n",
    "    'username':'gingerdeer632',\n",
    "    'password': pw\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b996385c-7f38-43c9-9e3b-695199a493be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply auth to future requests\n",
    "headers = {'User-Agent': 'MyAPI/0.0.1'}\n",
    "\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                   auth=auth, data=data, headers=headers)\n",
    "\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "headers['Authorization'] = f'bearer {TOKEN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d70b71e-c63d-4409-900b-ae17fc10426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial request\n",
    "r = requests.get('https://oauth.reddit.com/r/popular/hot',\n",
    "                headers=headers)\n",
    "# initialize dataframe\n",
    "df_r = pd.DataFrame(columns=['id','created_time','current_time','time_since_post','subreddit','title', 'contents','upvotes','downvotes','num_comments'])\n",
    "\n",
    "#initialize request queue\n",
    "reqs = []\n",
    "reqs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca045d4-8e16-4100-8b74-717e2ed1242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction funcs, only work in a for loop\n",
    "\n",
    "def extract_title(result):\n",
    "    try:\n",
    "        return result['data']['title']\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def extract_time(result):\n",
    "    try:\n",
    "        ts = datetime.datetime.fromtimestamp(result['data']['created_utc'])\n",
    "        return ts.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def extract_subreddit(result):\n",
    "    try:\n",
    "        return result['data']['subreddit']\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def extract_num_comments(result):\n",
    "    try:\n",
    "        return result['data']['num_comments']\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def extract_id(result):\n",
    "    try:\n",
    "        return result['kind'] + '_' + result['data']['id']\n",
    "    except:\n",
    "        return 'NaN'\n",
    "def extract_body(result):\n",
    "    try:\n",
    "        if not result['data']['selftext']:\n",
    "            url = result['data']['url']\n",
    "            is_photo = ['png','jpeg','jpg']\n",
    "            \n",
    "            if result['data']['is_video']:\n",
    "                return 'Video: ' + url\n",
    "            elif any(x in url for x in is_photo):\n",
    "                return 'Photo: ' + url\n",
    "            else:\n",
    "                return 'URL: ' + result['data']['url']\n",
    "        else:\n",
    "            return result['data']['selftext']\n",
    "    except:\n",
    "        return 'NaN'\n",
    "def extract_downvotes(result):\n",
    "    try:\n",
    "        score = result['data']['score']\n",
    "        ratio = result['data']['upvote_ratio']\n",
    "        return round((score*(ratio-1)) / (1-(2*ratio)))\n",
    "    except:\n",
    "        return 'NaN'\n",
    "def extract_upvotes(result):\n",
    "    try:\n",
    "        downvotes = extract_downvotes(result)\n",
    "        score = result['data']['score']\n",
    "        return score + downvotes\n",
    "    except:\n",
    "        return 'NaN'\n",
    "def extract_time_diff(result):\n",
    "    try:\n",
    "        current_dt = datetime.datetime.fromtimestamp(round(time.time()))\n",
    "        post_dt = datetime.datetime.fromtimestamp(result['data']['created_utc'])\n",
    "        time_d = current_dt - post_dt\n",
    "        return str(time_d)\n",
    "    except:\n",
    "        return 'NaN'\n",
    "def extract_num_awards(result):\n",
    "    try:\n",
    "        return result['data']['total_awards_received']\n",
    "    except:\n",
    "        return 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1701f899-5277-4dff-ae0e-f0e5c496b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill dataframe, change request to next page\n",
    "\n",
    "def scrape(reqs, headers):\n",
    "    r = reqs.pop(0)\n",
    "   \n",
    "    for post in r.json()['data']['children']:\n",
    "        global df_r\n",
    "        df_r = df_r.append({\n",
    "            'id': extract_id(post),\n",
    "            'created_time': extract_time(post),\n",
    "            'current_time': datetime.datetime.fromtimestamp(round(time.time())),\n",
    "            'time_since_post': extract_time_diff(post),\n",
    "            'subreddit': extract_subreddit(post),\n",
    "            'title': extract_title(post),\n",
    "            'contents': extract_body(post),\n",
    "            'upvotes': extract_upvotes(post),\n",
    "            'downvotes':extract_downvotes(post),\n",
    "            'num_comments': extract_num_comments(post)\n",
    "        }, ignore_index=True)\n",
    "            \n",
    "   \n",
    "    reqs.append(requests.get('https://oauth.reddit.com/r/popular/hot',\n",
    "                headers=headers, params={'after':extract_id(post)}))\n",
    "\n",
    "# save dataframe to csv occationally\n",
    "def save(DataFrame):\n",
    "    DataFrame.to_csv('./data/reddit_scrap.csv',mode='a',header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf293897-3dac-4c61-8e92-9b4474b06a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c36617b50b3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scrapes every minute\n",
    "# will run until interupted\n",
    "\n",
    "# Scheduler params for function param not changing with global variable\n",
    "schedule.every(60).seconds.do(scrape,reqs=reqs,headers=headers)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3f1b16-81ca-4d4f-94b7-3fff827ecaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually save after 30 minutes\n",
    "save(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b708b2a-f590-41a9-be1a-5806b30866bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
